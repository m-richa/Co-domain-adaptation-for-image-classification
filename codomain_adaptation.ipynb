{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codomain-adaptation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPuZ9utV3rXPp/td2RovPwg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-richa/Co-domain-adaptation-for-image-classification/blob/main/codomain_adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5yLU_HRwbkh"
      },
      "source": [
        "!git remote add origin https://<USERNAME>:<PASSWORD>@github.com/<USERNAME>/reponame.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4I2YS3wPTYE"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.layers import Flatten, Input\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_FsDZd5Pc58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c4df99-3266-4a25-9ad4-bf5d093f076c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkchSD8APgu8"
      },
      "source": [
        "!unzip -q photo.zip\n",
        "!unzip -q sketch.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykHFx9a4Pq-Q"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "src_path_train = '/content/photo/'\n",
        "trg_path = '/content/sketch/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdZxJSnXPv5O"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class MergedGenerators(Sequence):\n",
        "\n",
        "    def __init__(self, batch_size, generators=[], sub_batch_size=[]):\n",
        "        self.generators = generators\n",
        "        self.sub_batch_size = sub_batch_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(\n",
        "            sum([(len(self.generators[idx]) * self.sub_batch_size[idx])\n",
        "                 for idx in range(len(self.sub_batch_size))]) /\n",
        "            self.batch_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Getting items from the generators and packing them\"\"\"\n",
        "\n",
        "        X_batch = []\n",
        "        Y_batch = []\n",
        "        for generator in self.generators:\n",
        "            if generator.class_mode is None:\n",
        "                x1 = generator[index % len(generator)]\n",
        "                X_batch = [*X_batch, *x1]\n",
        "\n",
        "            else:\n",
        "                x1, y1 = generator[index % len(generator)]\n",
        "                X_batch = [*X_batch, *x1]\n",
        "                Y_batch = [*Y_batch, *y1]\n",
        "\n",
        "        if self.generators[0].class_mode is None:\n",
        "            return np.array(X_batch)\n",
        "        return np.array(X_batch), np.array(Y_batch)\n",
        "\n",
        "\n",
        "def build_datagenerator(dir1=None, dir2=None, batch_size=32):\n",
        "    n_images_in_dir1 = sum([len(files) for r, d, files in os.walk(dir1)])\n",
        "    n_images_in_dir2 = sum([len(files) for r, d, files in os.walk(dir2)])\n",
        "\n",
        "    # Have to set different batch size for two generators as number of images\n",
        "    # in those two directories are not same. As we have to equalize the image\n",
        "    # share in the generators\n",
        "    generator1_batch_size = int((n_images_in_dir1 * batch_size) /\n",
        "                                (n_images_in_dir1 + n_images_in_dir2))\n",
        "\n",
        "    generator2_batch_size = batch_size - generator1_batch_size\n",
        "\n",
        "    generator1 = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=5.,\n",
        "        horizontal_flip=True,\n",
        "    )\n",
        "\n",
        "    generator2 = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=5.,\n",
        "        horizontal_flip=True,\n",
        "    )\n",
        "\n",
        "    # generator2 has different image augmentation attributes than generaor1\n",
        "    generator1 = generator1.flow_from_directory(\n",
        "        dir1,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=generator1_batch_size,\n",
        "        shuffle=True,\n",
        "        seed=4,\n",
        "        interpolation=\"bicubic\",\n",
        "    )\n",
        "\n",
        "    generator2 = generator2.flow_from_directory(\n",
        "        dir2,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        color_mode='rgb',\n",
        "        class_mode=None,\n",
        "        batch_size=generator2_batch_size,\n",
        "        shuffle=True,\n",
        "        seed=4,\n",
        "        interpolation=\"bicubic\",\n",
        "    )\n",
        "\n",
        "    return MergedGenerators(\n",
        "        batch_size,\n",
        "        generators=[generator1, generator2],\n",
        "        sub_batch_size=[generator1_batch_size, generator2_batch_size])\n",
        "\n",
        "\n",
        "def train_datagen(batch_size=BATCH_SIZE):\n",
        "    datagen = build_datagenerator(dir1=src_path_train,\n",
        "                                  dir2=trg_path,\n",
        "                                  batch_size=batch_size)\n",
        "\n",
        "    print(\"Datagenerator length (Batch count):\", len(datagen))\n",
        "\n",
        "    for batch_count, image_batch in enumerate(datagen):\n",
        "        if batch_count == 1:\n",
        "            break\n",
        "\n",
        "        image_batch = np.array(image_batch)\n",
        "        #print(image_batch[0][1].shape)\n",
        "\n",
        "        #print(\"Images: \", image_batch.shape)\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(image_batch[0].shape[0]):\n",
        "            plt.subplot(1, batch_size, i + 1)\n",
        "            plt.imshow(image_batch[0][i], interpolation='nearest')\n",
        "            plt.axis('off')\n",
        "            plt.tight_layout()\n",
        "\n",
        "    return datagen\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKOZ138hj80u",
        "outputId": "22db43f5-2816-4de3-c955-f45bb2760e92"
      },
      "source": [
        "train_data_gen.__getitem__(1)[0][:2].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROiE_zBePUQJ",
        "outputId": "587ab277-7258-40a0-ae8e-ec1191dc53c9"
      },
      "source": [
        "class model(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(model, self).__init__()\n",
        "\n",
        "        self.input_layer = tf.keras.layers.Input(name=\"inp_img\", shape=(224,224,3,))\n",
        "        self.feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224,224,3,),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "        self.feature_extractor.trainable=False\n",
        "        self.l1 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.l2 = tf.keras.layers.Flatten()\n",
        "        self.l3 = tf.keras.layers.Dense(1024, activation=\"relu\")\n",
        "        self.l4 = tf.keras.layers.Dense(512, activation=\"relu\")\n",
        "        self.l5 =tf.keras.layers.Dense(7, activation=\"softmax\", name=\"logits\")\n",
        "\n",
        "        #super(model, self).__init__(inputs=self.input_layer ,outputs=self.l5,)\n",
        "    \n",
        "    def summary(self):\n",
        "        x = self.input_layer\n",
        "        model = Model(inputs=[x], outputs=self.call(x))\n",
        "        return model.summary()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.feature_extractor(inputs)\n",
        "        x.trainable = False\n",
        "\n",
        "        x = self.l1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.l4(x)\n",
        "        x = self.l5(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model = model()\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Total params: 26,214,279\n",
            "Trainable params: 2,626,567\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "v0qXYdlKUOzI",
        "outputId": "115d7b18-7dd3-41b8-a01b-5e65b04a4a18"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAAA8CAYAAAAaEIaPAAAABmJLR0QA/wD/AP+gvaeTAAAEk0lEQVR4nO2czWsTXRSHfxOaTL5KEjRGIQ3diAihi0R3upJCl9UodVsIiF24MVVQScGVEJNmUxU/FqWWJG1w5x9QCg1RobElYKgbsaDQQkJiRmqtPxfS4Y1p81q4bd683gdmc+bcM+c+XO5MGDIKSUIigllDuzv4PyFlCkTKFIiUKZCu3wO5XA6JRKIdvXQUs7OzTbGmlfnx40dks9kDaagTWV1d3dVP08rcZifzEmBmZgZDQ0M7npN7pkCkTIFImQKRMgUiZQpEyhSIlCkQKVMgUqZApEyBSJkCkTIFImUKRMoUSEfLDIfD6O7uhqIoKBQKfzTm/v37OHLkCBRFwaNHj4T209Eynz59iidPnuxpTCQSwcLCwr7009Ey/2t0vExFUdrdgo4QmclkEjabDQaDAcFgEB6PB0ajETabDYFAAGfPnkVPTw/MZjOcTidu3LjRMJ4kEokETp48CVVV4XK5MDg4iHfv3jXlxWIxnDhxAqqqwuFwYHR0tKmfra0tRKNR+Hw+WCwW9PX1IZPJiJhqa/gbmUyGO4T/lbGxMQJgPp9nvV7n+vo6BwYGCIAvX77k2toa6/U6r127RgAsFAr62Gg0SpPJxKmpKVYqFS4tLTEQCPDw4cP8/Pmznnf79m0qisJ4PM5yuUxN0zgxMUEAXFxc1PMikQhVVWU2m2W5XOatW7doMBj4+vVrkuTKygoB8OHDh3ueZws/M8Jl1mo1PTY5OUkAXF5e1mOvXr0iAKbTaZKkpmm02+28fPlyQ73tvLt37+p5VquV/f39DXmpVKpB5tevX2m1WhvqaZpGVVU5MjJCcv9k7uueaTKZAADfv3/XY0ajEQCwubkJACgWi/jy5QtOnTrVMPb06dMwmUzI5/MAgPfv30PTNJw7d67lNUulEjRNg9/v12MWiwVHjx5t2jZE0/YbUKVSAQDY7famc06nE7VaDcCv99UA4Ha7W9ar1+sAgDt37kBRFP348OEDNE0T2XoTbZfpdDoBQJf2TyqVCrxeLwDAbDYDADY2NlrW25Y9Pj4Okg1HLpcT2XoTbZfp9/tht9vx5s2bhng+n8e3b98QDAb1PIPBgLm5uZb1tp8a/vQXkUjaLtNsNuP69et48eIFnj9/jmq1iuXlZVy9ehXHjh3DlStXAPxacaFQCNlsFs+ePUO1WsXS0hIeP37cVG94eBipVAoPHjxAtVrF1tYWVldX8enTp/2dzB7uVruSTCZptVoJgL29vZyfn+e9e/focDgIgB6Ph9PT00yn0/R4PARAl8vFVCpFkvzx4wdjsRiPHz9Oo9FIl8vF8+fPs1QqNVynVqsxHA7z0KFDtNvtPHPmDKPRKAHQ6/Xy7du3JMmNjQ3evHmTPp+PXV1ddLvdDIVCLBaLjMfjeg82m40XLlzY01wP5NHob6Ftj0Z/G1KmQKRMgUiZApEyBSJlCkTKFIiUKRApUyBSpkCkTIFImQKRMgUiZQpEyhSIlCkQKVMgu/6r99KlSwfZR8ew/cp5J5pWZk9PDy5evLivDXUyXq93Vz8KKT/FIwj5KR6RSJkCkTIFImUK5CcyGR/XqjCWkAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv6Rart-cyt_"
      },
      "source": [
        "def weighted_cross_entropy_loss(logits):\n",
        "    logit_max = K.max(logits, 1)\n",
        "    y_true = K.argmax(logits)\n",
        "    \n",
        "    is_condition = logit_max>=0.95\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, logits)\n",
        "    weighted_loss = tf.multiply(logit_max, loss)\n",
        "    return tf.where(is_condition, weighted_loss, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwTdHAo1V7bh"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(\"Start of epoch %d\" % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, x_batch_train in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = final_model(x_batch_train[0])\n",
        "            # Compute reconstruction loss\n",
        "            loss = mse_loss_fn(x_batch_train, reconstructed)\n",
        "            loss += sum(vae.losses)  # Add KLD regularization loss\n",
        "\n",
        "        grads = tape.gradient(loss, vae.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "        loss_metric(loss)\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(\"step %d: mean loss = %.4f\" % (step, loss_metric.result()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2fplTmKHPr_"
      },
      "source": [
        "def loss_object(logits, labels):\n",
        "  loss1 = tf.keras.losses.categorical_crossentropy(labels, logits[:14])\n",
        "  loss2 = weighted_cross_entropy_loss(logits[14:])\n",
        "\n",
        "  return loss1, loss2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "joTje98HIrVE",
        "outputId": "0a6b80b2-c23b-46e6-edfa-32c2951431b9"
      },
      "source": [
        "train_data_gen =train_datagen(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n",
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:108: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 50 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS8kKNv2FSOo"
      },
      "source": [
        "\n",
        "\n",
        "def train_steps(train_data):\n",
        "  for i in range(5):\n",
        "    img_src = train_data_gen.__getitem__(i)[0]#[:10]\n",
        "    src_label = train_data_gen.__getitem__(i)[1]\n",
        "    print(train_data_gen.__getitem__(i)[0].shape)\n",
        "    print(train_data_gen.__getitem__(i)[1].shape)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(img_src, training=True)\n",
        "      loss_value1, loss_value2 = loss_object(logits, src_label)\n",
        "\n",
        "    print(logits.numpy())\n",
        "    print(loss_value1.numpy())\n",
        "    print(loss_value2.numpy())\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN8B7-RYJBav",
        "outputId": "048468dc-3625-423a-8c04-b971eac16697"
      },
      "source": [
        "train_steps(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 224, 224, 3)\n",
            "(14, 7)\n",
            "[[0.12817967 0.26491904 0.06202437 0.13155836 0.1774022  0.04456371\n",
            "  0.19135273]\n",
            " [0.12125965 0.27804053 0.05968409 0.13218895 0.17972888 0.04330906\n",
            "  0.18578881]\n",
            " [0.12258556 0.2758477  0.06119408 0.13103262 0.17882416 0.04352858\n",
            "  0.18698725]\n",
            " [0.11671048 0.28475344 0.05687701 0.13341163 0.17867918 0.04287066\n",
            "  0.18669756]\n",
            " [0.12721507 0.2749538  0.06427386 0.13331972 0.1792745  0.04330884\n",
            "  0.17765422]\n",
            " [0.12318549 0.27662414 0.05891582 0.13484283 0.17935632 0.04236877\n",
            "  0.18470664]\n",
            " [0.12218942 0.2727019  0.05707665 0.13353206 0.17737924 0.0436166\n",
            "  0.1935042 ]\n",
            " [0.12161645 0.26831278 0.06177183 0.1300962  0.18333259 0.04516643\n",
            "  0.18970376]\n",
            " [0.12298767 0.2741636  0.05798587 0.13289833 0.17898938 0.04324796\n",
            "  0.18972717]\n",
            " [0.12691316 0.27675912 0.06000006 0.13451399 0.17730992 0.04270194\n",
            "  0.18180184]\n",
            " [0.12896097 0.2849133  0.06001814 0.12686066 0.19391017 0.03928415\n",
            "  0.1660526 ]\n",
            " [0.12609693 0.26478627 0.06205224 0.13359573 0.17971073 0.04491132\n",
            "  0.18884674]\n",
            " [0.12214781 0.27003083 0.05808435 0.1364014  0.17749351 0.04536521\n",
            "  0.19047685]\n",
            " [0.12475811 0.26648897 0.06344522 0.13257359 0.1807335  0.04525568\n",
            "  0.1867449 ]\n",
            " [0.16554736 0.34040233 0.07894805 0.09873198 0.17801829 0.02998872\n",
            "  0.10836335]\n",
            " [0.14127925 0.2839745  0.07438283 0.14415547 0.17517868 0.03852589\n",
            "  0.14250343]\n",
            " [0.16501462 0.29776838 0.07674144 0.11669451 0.1796395  0.03612233\n",
            "  0.12801921]\n",
            " [0.15557286 0.28815106 0.06766141 0.1210976  0.1815783  0.03420301\n",
            "  0.15173584]\n",
            " [0.15215643 0.33131224 0.08031808 0.12107305 0.17447186 0.03298005\n",
            "  0.10768827]\n",
            " [0.15661074 0.3070124  0.07163107 0.11923936 0.1832359  0.03566622\n",
            "  0.1266044 ]\n",
            " [0.1598401  0.29209438 0.07709649 0.1179356  0.1939968  0.03496744\n",
            "  0.12406919]\n",
            " [0.13602385 0.27366272 0.06790219 0.127031   0.1943325  0.03784471\n",
            "  0.16320297]\n",
            " [0.13349262 0.28845257 0.06513    0.13150539 0.17559406 0.04262362\n",
            "  0.16320173]\n",
            " [0.14776745 0.29607055 0.07966253 0.12634918 0.18398337 0.0350896\n",
            "  0.13107742]\n",
            " [0.15294243 0.27335814 0.07142764 0.14090894 0.17549619 0.03920312\n",
            "  0.14666344]\n",
            " [0.15610674 0.30965626 0.08234853 0.12227952 0.18357886 0.03583968\n",
            "  0.11019033]\n",
            " [0.15333387 0.28624144 0.07132838 0.13187042 0.1753864  0.03828625\n",
            "  0.14355321]\n",
            " [0.1457327  0.2748805  0.07069387 0.14689898 0.17426018 0.04142276\n",
            "  0.14611104]\n",
            " [0.17380956 0.29060706 0.07984221 0.1168505  0.17584516 0.03721322\n",
            "  0.12583229]\n",
            " [0.15620749 0.3245826  0.07891388 0.11334487 0.17574444 0.03142544\n",
            "  0.1197812 ]\n",
            " [0.14794256 0.3221776  0.07416718 0.12417495 0.1721635  0.03327276\n",
            "  0.12610146]\n",
            " [0.16079389 0.3173347  0.07853319 0.1205501  0.17430827 0.03456653\n",
            "  0.11391331]\n",
            " [0.13875356 0.27793443 0.06547466 0.13070081 0.18345061 0.04063464\n",
            "  0.16305125]\n",
            " [0.1451662  0.27873445 0.07305774 0.12685676 0.18441486 0.0374968\n",
            "  0.15427318]\n",
            " [0.16510732 0.31336397 0.07622653 0.1162126  0.18041074 0.03175712\n",
            "  0.11692175]\n",
            " [0.14601092 0.32318527 0.06915341 0.13230418 0.18670657 0.03048218\n",
            "  0.1121576 ]\n",
            " [0.15858021 0.31092858 0.08235752 0.11069999 0.18237163 0.03660053\n",
            "  0.1184615 ]\n",
            " [0.16529034 0.29605433 0.08025652 0.12669182 0.17368081 0.03756796\n",
            "  0.12045828]\n",
            " [0.14630798 0.30248573 0.06942705 0.12415915 0.17258318 0.03768702\n",
            "  0.14734994]\n",
            " [0.14228848 0.3133314  0.06203048 0.12412126 0.17548019 0.03725827\n",
            "  0.14548995]\n",
            " [0.1427877  0.30047148 0.07974583 0.13068482 0.19170864 0.0342714\n",
            "  0.12033015]\n",
            " [0.1573763  0.3373135  0.07763135 0.10641271 0.18275113 0.03238101\n",
            "  0.10613394]\n",
            " [0.13867657 0.29192668 0.07360907 0.13865918 0.17364106 0.03948193\n",
            "  0.14400558]\n",
            " [0.13967562 0.2610736  0.07039521 0.13681296 0.18204217 0.04479755\n",
            "  0.16520283]\n",
            " [0.15910679 0.3091979  0.07299636 0.11770306 0.16968891 0.03775819\n",
            "  0.13354878]\n",
            " [0.14186731 0.3099514  0.07481965 0.12880445 0.1970287  0.03458004\n",
            "  0.11294847]\n",
            " [0.15654953 0.31108797 0.07350078 0.12418528 0.16608205 0.03497009\n",
            "  0.13362429]\n",
            " [0.16395488 0.28611934 0.07872081 0.11759152 0.18624622 0.03757808\n",
            "  0.12978904]\n",
            " [0.1488763  0.2981382  0.06688857 0.12605405 0.17639042 0.03785846\n",
            "  0.145794  ]\n",
            " [0.14608608 0.2833805  0.06722979 0.12901586 0.1765573  0.03897064\n",
            "  0.15875983]]\n",
            "[1.6536368 2.8186898 1.6767149 3.1495674 2.015005  1.2850956 2.8633602\n",
            " 1.6622915 1.7204288 2.8134098 2.8131084 1.7164068 1.7288213 1.7107317]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}