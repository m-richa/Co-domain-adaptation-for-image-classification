{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "codomain-adaptation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrcBKzxqvyUh0fT6oS5+KS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-richa/Co-domain-adaptation-for-image-classification/blob/main/codomain_adaptation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5yLU_HRwbkh"
      },
      "source": [
        "#!git remote add origin https://<USERNAME>:<PASSWORD>@github.com/<USERNAME>/reponame.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4I2YS3wPTYE"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.layers import Flatten, Input\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "import tensorflow.keras.backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_FsDZd5Pc58"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkchSD8APgu8"
      },
      "source": [
        "#!unzip -q photo.zip\n",
        "!unzip -q sketch.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykHFx9a4Pq-Q"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 50\n",
        "EPOCHS = 1\n",
        "src_path_train = '/content/photo/'\n",
        "trg_path = '/content/sketch/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdZxJSnXPv5O"
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "class MergedGenerators(Sequence):\n",
        "\n",
        "    \n",
        "\n",
        "    def __init__(self, batch_size, generators=[], sub_batch_size=[]):\n",
        "        self.generators = generators\n",
        "        self.sub_batch_size = sub_batch_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(\n",
        "            sum([(len(self.generators[idx]) * self.sub_batch_size[idx])\n",
        "                 for idx in range(len(self.sub_batch_size))]) /\n",
        "            self.batch_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Getting items from the generators and packing them\"\"\"\n",
        "\n",
        "        X_batch = []\n",
        "        Y_batch = []\n",
        "        for generator in self.generators:\n",
        "            if generator.class_mode is None:\n",
        "                x1 = generator[index % len(generator)]\n",
        "                X_batch = [*X_batch, *x1]\n",
        "\n",
        "            else:\n",
        "                x1, y1 = generator[index % len(generator)]\n",
        "                X_batch = [*X_batch, *x1]\n",
        "                Y_batch = [*Y_batch, *y1]\n",
        "\n",
        "        if self.generators[0].class_mode is None:\n",
        "            return np.array(X_batch)\n",
        "        return np.array(X_batch), np.array(Y_batch)\n",
        "\n",
        "\n",
        "def build_datagenerator(dir1=None, dir2=None, batch_size=32):\n",
        "\n",
        "\n",
        "    seed = random.randint(0, 100)\n",
        "    print(\"seed={}\".format(seed))\n",
        "    n_images_in_dir1 = sum([len(files) for r, d, files in os.walk(dir1)])\n",
        "    n_images_in_dir2 = sum([len(files) for r, d, files in os.walk(dir2)])\n",
        "\n",
        "    # Have to set different batch size for two generators as number of images\n",
        "    # in those two directories are not same. As we have to equalize the image\n",
        "    # share in the generators\n",
        "    generator1_batch_size = int((n_images_in_dir1 * batch_size) /\n",
        "                                (n_images_in_dir1 + n_images_in_dir2))\n",
        "\n",
        "    generator2_batch_size = batch_size - generator1_batch_size\n",
        "\n",
        "    generator1 = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=5.,\n",
        "        horizontal_flip=True,\n",
        "    )\n",
        "\n",
        "    generator2 = ImageDataGenerator(\n",
        "        rescale=1. / 255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=5.,\n",
        "        horizontal_flip=True,\n",
        "    )\n",
        "\n",
        "    # generator2 has different image augmentation attributes than generaor1\n",
        "    generator1 = generator1.flow_from_directory(\n",
        "        dir1,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        color_mode='rgb',\n",
        "        class_mode='categorical',\n",
        "        batch_size=generator1_batch_size,\n",
        "        shuffle=True,\n",
        "        seed=seed,\n",
        "        interpolation=\"bicubic\",\n",
        "    )\n",
        "\n",
        "    generator2 = generator2.flow_from_directory(\n",
        "        dir2,\n",
        "        target_size=(IMG_SIZE, IMG_SIZE),\n",
        "        color_mode='rgb',\n",
        "        class_mode=None,\n",
        "        batch_size=generator2_batch_size,\n",
        "        shuffle=True,\n",
        "        seed=seed,\n",
        "        interpolation=\"bicubic\",\n",
        "    )\n",
        "\n",
        "    return MergedGenerators(\n",
        "        batch_size,\n",
        "        generators=[generator1, generator2],\n",
        "        sub_batch_size=[generator1_batch_size, generator2_batch_size])\n",
        "\n",
        "\n",
        "def train_datagen(batch_size=BATCH_SIZE):\n",
        "    datagen = build_datagenerator(dir1=src_path_train,\n",
        "                                  dir2=trg_path,\n",
        "                                  batch_size=batch_size)\n",
        "\n",
        "    print(\"Datagenerator length (Batch count):\", len(datagen))\n",
        "    \n",
        "    '''for batch_count, image_batch in enumerate(datagen):\n",
        "        if batch_count == 1:\n",
        "            break\n",
        "\n",
        "        image_batch = np.array(image_batch)\n",
        "        #print(image_batch[0][1].shape)\n",
        "\n",
        "        #print(\"Images: \", image_batch.shape)\n",
        "        \n",
        "        plt.figure(figsize=(10, 10))\n",
        "        for i in range(10):\n",
        "            plt.subplot(1, batch_size, i + 1)\n",
        "            plt.imshow(image_batch[0][i], interpolation='nearest')\n",
        "            plt.axis('off')\n",
        "            plt.tight_layout()'''\n",
        "\n",
        "    return datagen\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKOZ138hj80u"
      },
      "source": [
        "train_data_gen.__getitem__(1)[0][:2].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROiE_zBePUQJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c1e917e-c2a4-451d-9aea-9fa67b847918"
      },
      "source": [
        "class model(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(model, self).__init__()\n",
        "\n",
        "        self.input_layer = tf.keras.layers.Input(name=\"inp_img\", shape=(224,224,3,))\n",
        "        self.feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224,224,3,),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "        self.feature_extractor.trainable=False\n",
        "        self.l1 = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.l2 = tf.keras.layers.Flatten()\n",
        "        self.l3 = tf.keras.layers.Dense(1024, activation=\"relu\")\n",
        "        self.l4 = tf.keras.layers.Dense(512, activation=\"relu\")\n",
        "        self.l5 =tf.keras.layers.Dense(7, activation=\"softmax\", name=\"logits\")\n",
        "\n",
        "        #super(model, self).__init__(inputs=self.input_layer ,outputs=self.l5,)\n",
        "    \n",
        "    def summary(self):\n",
        "        x = self.input_layer\n",
        "        model = Model(inputs=[x], outputs=self.call(x))\n",
        "        return model.summary()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.feature_extractor(inputs)\n",
        "        x.trainable = False\n",
        "\n",
        "        x = self.l1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.l4(x)\n",
        "        x = self.l5(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "'''if __name__ == '__main__':\n",
        "    model = model()\n",
        "    model.summary()'''"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"if __name__ == '__main__':\\n    model = model()\\n    model.summary()\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0qXYdlKUOzI"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv6Rart-cyt_"
      },
      "source": [
        "def weighted_cross_entropy_loss(logits):\n",
        "    logit_max = K.max(logits, 1)\n",
        "    y_true = K.argmax(logits)\n",
        "    \n",
        "    is_condition = logit_max>=0.95\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(y_true, logits)\n",
        "    weighted_loss = tf.multiply(logit_max, loss)\n",
        "    return tf.where(is_condition, weighted_loss, 0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2fplTmKHPr_"
      },
      "source": [
        "def loss_object(logits, labels):\n",
        "  loss1 = tf.keras.losses.categorical_crossentropy(labels, logits[:14])\n",
        "  loss2 = weighted_cross_entropy_loss(logits[14:])\n",
        "  print(logits[14])\n",
        "  loss3 = tf.reduce_mean([x*tf.math.log(x) for x in logits[14:]])\n",
        "\n",
        "  return 4*loss1, 2*loss2, 0.0 #loss3"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deoDYMj3173w"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS8kKNv2FSOo"
      },
      "source": [
        "BATCH_SIZE= 100\n",
        "datagen = build_datagenerator(dir1=src_path_train,\n",
        "                                  dir2=trg_path,\n",
        "                                  batch_size=batch_size)\n",
        "\n",
        "EPOCHS = len(datagen)\n",
        "\n",
        "def train_steps(optimizer, model, step):\n",
        "\n",
        "\n",
        "  train_data_gen = train_datagen(BATCH_SIZE)\n",
        "  \n",
        "  loss_1, loss_2, loss_3, loss_value = [], [], [], []\n",
        "  #pbar1 = tqdm(total=112, position=0, leave=True, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ')\n",
        "  #pbar2 = tqdm(total=112, position=0, leave=True, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ')\n",
        "  #pbar3 = tqdm(total=112, position=0, leave=True, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ')\n",
        "  pbar = tqdm(total=112, position=0, leave=True, bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} ')\n",
        "\n",
        "  for i in range(len(train_data_gen)):\n",
        "    img_src = train_data_gen.__getitem__(i)[0]#[:10]\n",
        "    src_label = train_data_gen.__getitem__(i)[1]\n",
        "    #print(train_data_gen.__getitem__(i)[0].shape)\n",
        "    #print(train_data_gen.__getitem__(i)[1].shape)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(img_src, training=True)\n",
        "      loss_value1, loss_value2, loss_value3 = loss_object(logits, src_label)\n",
        "      total_value = tf.reduce_mean(loss_value1) + tf.reduce_mean(loss_value2) + tf.reduce_mean(loss_value3)\n",
        "  \n",
        "    gradients = tape.gradient(total_value, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "    loss_value.append(total_value)\n",
        "    loss_1.append(tf.reduce_mean(loss_value1))\n",
        "    loss_2.append(tf.reduce_mean(loss_value2))\n",
        "    loss_3.append(tf.reduce_mean(loss_value3))\n",
        "      \n",
        "    #train_acc_metric(y_batch_train, logits)\n",
        "    #pbar1.set_description(\"Training loss1 for step %s: %.4f\" % (int(step), float(tf.reduce_mean(loss_1))))\n",
        "    #pbar2.set_description(\"Training loss2 for step %s: %.4f\" % (int(step), float(tf.reduce_mean(loss_2))))\n",
        "    #pbar3.set_description(\"Training loss3 for step %s: %.4f\" % (int(step), float(tf.reduce_mean(loss_3))))\n",
        "    pbar.set_description(\"Training loss for step %s: %.4f\" % (int(step), float(tf.reduce_mean(loss_value))))\n",
        "    #pbar1.update()\n",
        "    #pbar2.update()\n",
        "    #pbar3.update()\n",
        "    pbar.update()\n",
        "  \n",
        "  return loss_value, loss_1, loss_2, loss_3\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qyTUZYNXHsC"
      },
      "source": [
        "del model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agpiZHr4Byo3"
      },
      "source": [
        "#del model\n",
        "model = model()\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN8B7-RYJBav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff4ca6e5-8c2d-49ff-c336-eb114bf99b48"
      },
      "source": [
        "\n",
        "\n",
        "# Iterate over epochs.\n",
        "epochs = 20\n",
        "epochs_train_losses, epochs_train_losses1, epochs_train_losses2, epochs_train_losses3 = [], [], [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch,))\n",
        "  \n",
        "  losses_train, loss_1, loss_2, loss_3 = train_steps(optimizer, model, epoch)\n",
        "\n",
        "  losses_train_mean = np.mean(losses_train)\n",
        "  losses_train_mean1 = np.mean(loss_1)\n",
        "  losses_train_mean2 = np.mean(loss_2)\n",
        "  losses_train_mean3 = np.mean(loss_3)\n",
        "\n",
        "  epochs_train_losses.append(losses_train_mean)\n",
        "  epochs_train_losses.append(losses_train_mean1)\n",
        "  epochs_train_losses.append(losses_train_mean2)\n",
        "  epochs_train_losses.append(losses_train_mean3)\n",
        "\n",
        "  print('\\n Epoch %s: Train loss: %.4f  Loss1: %.4f, Loss2: %.4f, Loss3: %.4f' % (epoch, float(losses_train_mean), float(losses_train_mean1), float(losses_train_mean2), float(losses_train_mean3)))\n",
        "  \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n",
            "seed=46\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 0: 8.2033: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 0: Train loss: 8.2033  Loss1: 8.1792, Loss2: 0.0241, Loss30.0000\n",
            "Start of epoch 1\n",
            "seed=74\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 1: 7.1697: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1: Train loss: 7.1697  Loss1: 7.1697, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 2\n",
            "seed=35\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 2: 6.7661: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 2: Train loss: 6.7661  Loss1: 6.7661, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 3\n",
            "seed=32\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 3: 6.4703: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 3: Train loss: 6.4703  Loss1: 6.4703, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 4\n",
            "seed=56\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 4: 6.2533: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 4: Train loss: 6.2533  Loss1: 6.2533, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 5\n",
            "seed=16\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 5: 6.1001: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 5: Train loss: 6.1001  Loss1: 6.1001, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 6\n",
            "seed=50\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 6: 5.9452: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 6: Train loss: 5.9452  Loss1: 5.9446, Loss2: 0.0006, Loss30.0000\n",
            "Start of epoch 7\n",
            "seed=92\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 7: 5.8979: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 7: Train loss: 5.8979  Loss1: 5.8973, Loss2: 0.0006, Loss30.0000\n",
            "Start of epoch 8\n",
            "seed=90\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 8: 5.8656: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 8: Train loss: 5.8656  Loss1: 5.8656, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 9\n",
            "seed=52\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 9: 5.7720: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 9: Train loss: 5.7720  Loss1: 5.7714, Loss2: 0.0006, Loss30.0000\n",
            "Start of epoch 10\n",
            "seed=63\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 10: 5.6098: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 10: Train loss: 5.6098  Loss1: 5.6093, Loss2: 0.0006, Loss30.0000\n",
            "Start of epoch 11\n",
            "seed=21\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 11: 5.6504: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 11: Train loss: 5.6504  Loss1: 5.6498, Loss2: 0.0006, Loss30.0000\n",
            "Start of epoch 12\n",
            "seed=79\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 12: 5.5926: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 12: Train loss: 5.5926  Loss1: 5.5920, Loss2: 0.0006, Loss30.0000\n",
            "Start of epoch 13\n",
            "seed=61\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 13: 5.5434: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 13: Train loss: 5.5434  Loss1: 5.5434, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 14\n",
            "seed=100\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 14: 5.4293: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 14: Train loss: 5.4293  Loss1: 5.4288, Loss2: 0.0006, Loss30.0000\n",
            "Start of epoch 15\n",
            "seed=43\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 15: 5.4250: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 15: Train loss: 5.4250  Loss1: 5.4250, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 16\n",
            "seed=42\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 16: 5.4542: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 16: Train loss: 5.4542  Loss1: 5.4542, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 17\n",
            "seed=17\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 17: 5.4723: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 17: Train loss: 5.4723  Loss1: 5.4723, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 18\n",
            "seed=27\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 18: 5.4059: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 18: Train loss: 5.4059  Loss1: 5.4059, Loss2: 0.0000, Loss30.0000\n",
            "Start of epoch 19\n",
            "seed=88\n",
            "Found 1670 images belonging to 7 classes.\n",
            "Found 3929 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Datagenerator length (Batch count): 112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss for step 19: 5.5059: 100%|██████████| 112/112 "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 19: Train loss: 5.5059  Loss1: 5.5059, Loss2: 0.0000, Loss30.0000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}